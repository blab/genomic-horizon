\documentclass[11pt,oneside,letterpaper]{article}
% \documentclass[9pt,lineno]{elife}

% graphicx package, useful for including eps and pdf graphics
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{subfig}
%\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% basic packages
\usepackage{color}
\usepackage{parskip}
\usepackage{float}
\usepackage{microtype}
\usepackage{url}
\usepackage[T1]{fontenc}
\urlstyle{same}

% \setkeys{Gin}{draft} %% draft mode

% \usepackage[hidelinks]{hyperref}
% \hypersetup{colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black}

\usepackage{longtable}
\usepackage[]{algorithm2e}

% reference figures across documents
\usepackage{xr}
%\externaldocument{mers-structure_supp}

% text layout
\usepackage{geometry}
\geometry{textwidth=15cm} % 15.25cm for single-space, 16.25cm for double-space
\geometry{textheight=22cm} % 22cm for single-space, 22.5cm for double-space

% helps to keep figures from being orphaned on a page by themselves
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}

% bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,font=small]{caption}

% review layout with double-spacing
%\usepackage{setspace}
%\doublespacing
%\captionsetup{labelfont=bf,labelsep=period,font=doublespacing}

% cite package, to clean up citations in the main text. Do not remove.
%\usepackage{cite}
\usepackage{natbib}
%\renewcommand\citepleft{(}
%\renewcommand\citepright{)}
%\renewcommand\citepform[1]{\textsl{#1}}

\usepackage{amsmath}

%\usepackage{lineno}
%\linenumbers

% Remove brackets from numbering in list of References
%\renewcommand\refname{\large References}
%\makeatletter
%\renewcommand{\@biblabel}[1]{\quad#1.}
%\makeatother

\usepackage{authblk}
\renewcommand\Authands{ \& }
\renewcommand\Authfont{\normalsize \bf}
\renewcommand\Affilfont{\small \normalfont}
\makeatletter
\renewcommand\AB@affilsepx{, \protect\Affilfont}
\makeatother

% comments
%\usepackage{ulem}
\definecolor{purple}{rgb}{0.459,0.109,0.538}
\def\tb#1#2{\sout{#1} \textcolor{purple}{#2}}
\def\tbc#1{\textcolor{purple}{[#1]}}
\def\gdc#1{\textcolor{blue}{[#1]}}

% symbols
% \newcommand{\chiSq}{\chi^{2}_{df}} %LM: ancient DNA? =P %GD: quite :)
% \newcommand{\dtmrca}{\Delta_\mathrm{TMRCA}}
% \newcommand{\undtmrca}{\delta_\mathrm{TMRCA}}
% \newcommand{\dspr}{d_\mathrm{SPR}}


%%% Comments from lab meeting:
% - HIV in contour plot
% - time variation across a single mutation in RTT
% - review distances*probability
% - location inference - is the true location in the 95% set?
% - bias in collection impact on correlates of migration
% - mention that GLM is broad scale patterns and easy to get at
% - more focus on benefits of genomic epi
% - talk about impact of unsampled diversity i.e. whole clades missing
% - ancestry plots for all tips/summary across all tips. masked tip ancestry?
% - bar plot of mean waiting times between whole genomes and subgenomic fragments


%%% TITLE %%%
\title{\vspace{1.0cm} \LARGE \bf The ability of single genes vs full genomes to resolve time and space in outbreak analysis}

\author[1,2$\ast$]{Gytis Dudas}
\author[1]{Trevor Bedford}

\affil[1]{Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA, USA}
\affil[2]{Gothenburg Global Biodiversity Center, Gothenburg, Sweden}
\affil[$\ast$]{Corresponding author (gdudas@fredhutch.org)}
\begin{document}

\maketitle

\begin{abstract}
% Inexpensive pathogen genome sequencing has transformed the field of genetic epidemiology into genomic epidemiology.
Inexpensive pathogen genome sequencing has had a transformative effect on the field of phylodynamics, where ever increasing volumes of data have promised real-time insight into outbreaks of infectious disease.
As well as the sheer volume of pathogen isolates being sequenced, the sequencing of whole pathogen genomes, rather than select loci, has allowed phylogenetic analyses to be carried out at finer time scales, often approaching serial intervals for infections caused by rapidly evolving RNA viruses.
Despite its utility, whole genome sequencing of pathogens has not been adopted universally and targeted sequencing of loci is common in some pathogen-specific fields.
In this study we aim to highlight the utility of sequencing whole genomes of pathogens by re-analysing a well-characterised collection of Ebola virus sequences in the form of complete viral genomes ($\sim$19kb long) or the rapidly evolving glycoprotein (GP, $\sim$2kb long) gene.
We quantify changes in phylogenetic, temporal, and spatial inference resolution as a result of this reduction in data and compare these to theoretical expectations.
We propose a simple intuitive metric for quantifying temporal resolution, \textit{i.e.} the time scale over which sequence data might be informative of various processes as a quick back-of-the-envelope calculation of statistical power available to molecular clock analyses.
% We quantify the changes in phylogenetic, temporal, and spatial inference resolution available to researchers when complete virus genomes are used ($\sim$19kb long) versus just the rapidly evolving glycoprotein (GP) gene ($\sim$2kb long) of Ebola virus in West Africa.

% By quantifying errors in phylogenetic reconstruction we hope to persuade researchers looking to sequence pathogens during outbreaks of the utility of complete genome sequencing.
% We further generalise our results by relating four parameters - probability, evolutionary rate, alignment length and waiting times - that determine how much information can be encoded by evolving pathogen lineages via mutations, which can help guide future sequencing studies.
% \tbc{The use of `probability', etc... here is a bit opaque.'}
\end{abstract}

\pagebreak

\section*{Introduction}
The combination of decreasing cost of sequencing and the unparalleled insight it offers have led to the adoption of pathogen genetic sequencing as one of the most effective tools in a modern epidemiologist's toolkit.
When coupled with sophisticated models of evolution, pathogen sequences can be used to look into epidemiological features such as cryptic transmission \citep{faria_establishment_2017}, migration \citep{lemey_bayesian_2009,lemey_unifying_2014}, and origins \citep{smith_origins_2009} of infectious diseases, amongst others.
Pathogen sequences also contain information about past temporal dynamics before sequence data have been collected \citep{raghwani_origin_2012} due to the pattern of shared and unique mutations inherited from preceding generations.
Molecular phylogenetic approaches rely on decoding these patterns of shared mutations into a nested graph known as the phylogenetic tree.
Pathogens often have short generation times and some, like RNA viruses, also possess polymerases with low replication fidelity such that mutations are generated at a rapid pace \citep{drummond_measurably_2003,biek_measurably_2015} leading to fast differentiation of pathogen lineages at the genetic level as they spread.
With appropriate sampling and information (``metadata'') about sequences, historic population dynamics can be inferred and quantified from pathogen phylogenies.
Changes in pathogen population sizes over time \citep{pybus_integrated_2000}, inference of unobserved ancestral states \citep{lemey_bayesian_2009,dudas_mers-cov_2018}, correlates of processes \citep{faria_simultaneously_2013,lemey_unifying_2014,dudas_virus_2017}, and overall phylodynamic \citep{grenfell_unifying_2004} patterns can be inferred from molecular phylogenies and used to understand patterns of pathogen transmission at a number of scales.

Before widespread adoption of high-throughput sequencing limitations and costs led to amplification and sequencing of short fragments of pathogen genomes \citep{jin_genetic_1999,jin_proposal_2005}.
These subgenomic fragments were often chosen for their diversity, such as viral surface glycoproteins that experience selective pressures from vertebrate immune systems, or their utility, such as routine sequencing of HIV \textit{pol} gene to test for drug resistance \citep{kaye_phylogenetic_2008,rhee_human_2003}.
Whilst subgenomic fragments of pathogens are very accurate and specific as diagnostic markers and informative about long-term evolution, their length (dictated by the compromise between information content and ease of sequencing) limits their utility in detailed molecular epidemiology investigations, for example during outbreaks \citep{wohl_co-circulating_2018}, as only mutations occurring within the small region of the genome that is sequenced are available for phylogenetic inference.

Molecular clocks have been particularly useful in molecular epidemiology, where the accumulation of mutations between sequences is used as a noisy approximation for elapsed time, given either times of events in the phylogeny (sequence dates or dates of common ancestors) or a previously determined molecular clock rate.
% Mutations, prior to the action of selection, occur randomly across a genome via misincorporation of nucleotides during replication by the polymerase.
% Many of these mutations are filtered out by selection if they adversely affect protein function, with leftover mutations being beneficial, neutral, or mildly deleterious.
Generally, neutral pathogen variation at the nucleotide level ebbs and flows under the forces of population genetics, unlike beneficial or deleterious variation which tends to either fix or be purged rapidly, respectively.
Due to their random and discrete nature, mutations are modelled as a Poisson process \citep{yang_computational_2006} where the waiting time $t$ for observing a mutation at a single site is exponentially distributed with evolutionary rate parameter $R$.
The probability of observing 0 mutations at a single site after time $t$ is $e^{-Rt}$ and the probability of at least one mutation is therefore $1-e^{-Rt}$.
Higher evolutionary rates \textit{R} or waiting times \textit{t} result in higher probabilities of observing at least one mutation at the site in question.
Since sites are assumed to evolve independently, the probability of observing at least one mutation across \textit{L} sites is
\begin{equation}
  P = 1-e^{-RLt},
\end{equation}
where \textit{RL} is expressed in substitutions per year (rate in substitutions per site per year multiplied by number of sites).
Under a given evolutionary rate \textit{R}, and sequence length \textit{L}, we can rearrange the equation to quantify the mean waiting time for at least one mutation:
\begin{equation}
  t = \frac{1}{RL}
  \label{horizon}
\end{equation}
When the evolutionary rate \textit{R} or sequence length \textit{L} are low mean waiting times are lengthened and \textit{vice versa}.
Since both maximum plausible evolutionary rates and genome length are largely dictated by deleterious mutation load \citep{gago_extremely_2009}, neither quantity will vary substantially for a given pathogen, though individually $R$ and $L$ can vary substantially, where for example viruses have high $R$ and low $L$ on average, and bacteria have higher $L$ but lower $R$.
% Because of these natural constraints there is thus a lower limit to how many mutations can be expected to occur in a given length of sequence evolving at a particular evolutionary rate.
% We thus refer to the mean waiting time for a mutation as the temporal horizon, which reflects a theoretical temporal resolution over which mutations arise and are available for phylogenetic inference in a study system.

In this study we quantify how much information relevant to phylodynamic analysis is lost when shorter genomic regions are used instead of full genomes.
By focusing our attention on a subset (600 sequences) of a well-characterised genomic sequence data (comprised of >1600 viral genomes) set derived from the West African Ebola virus epidemic of 2013-2015 \citep{dudas_virus_2017} we estimate loss in precision and accuracy of molecular clock models and phylogeographic inference methods when only the glycoprotein gene (GP), a region representing just 10\% of the viral genome, is analysed despite GP evolving at rates faster than the genomic average.
Our methods rely on masking tip dates and locations for 60 (10\%) of the sequences in a classic training-testing split, where we re-infer these parameters as latent variables in MCMC.
We show that this reduction in data not only leads to severe convergence issues in Markov chain Monte Carlo (MCMC) analyses by removing the constraints additional data impose on plausible parameter space but can also result in unreliable tip date and location inference.
Despite achieving much better temporal resolution when using complete viral genomes we still find residual error caused by inherent randomness of mutations which is close to theoretical expectations (Eq \ref{horizon}).
We refer to this as the temporal horizon, \textit{i.e.} a temporal resolution limit where population processes occurring at a rate faster than the rate at which mutations enter and are observed in a population will not be captured with high fidelity, even with genome sequences.
% As such, pathogen genomes have an inherent temporal resolution limit, where processes occurring at a rate lower than the rate of evolution of a given pathogen will not be recovered reliably using currently standard phylogenetic methods.
% We refer to this as the temporal horizon and express it as the mean waiting time until at least one mutation occurs and differentiates a pair of evolving sequences.
 % which is already substantial for fine scale epidemiology and that sequencing subgenomic fragments of a pathogen results in loss of information that can make sequence data unreliable beyond diagnostics and typing.
% In order to highlight how much information is lost and to relate the concept of temporal horizon with real data we use a subset of a well-characterised dataset of Ebola virus genomes from West Africa collected in 2014-2015 \citep{dudas_virus_2017}.
% By analysing both complete viral genomes and the same dataset reduced to just the surface glycoprotein GP (corresponding with just 10\% of all genomic sites), we show substantial loss of predictive power, incorrect or unreliable reconstructions of past events, and migration model, despite increased evolutionary rate in GP compared to complete genome.
% We hope that analyses presented here may serve as a guide to researchers in the field of genetic epidemiology of how to think about the statistical power of sequence data itself, as well as encouragement to model developers to address the widening rift between data volumes and methods used to analyse them.

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{figures/fig1_trees.png}
	\caption{\textbf{Phylogenies of West African Ebola virus genomes (top) or GP sequences (bottom).}
	Temporal phylogenies recovered using BEAST are shown on the left, maximum likelihood phylogenies recovered with RAxML are on the right.
  Tips are coloured based on country (Sierra Leone in blue, Liberia in red, Guinea in green) and location (lighter colours indicate administrative divisions lying towards west of the country).
  Tips outlined in white indicate the 60 chosen for date and location masking, ticks to the right of phylogenies indicate the y positions of masked tips, coloured by their true location.
  In temporal phylogenies branches are also coloured based on GLM-inferred ancestral locations.
  Nodes in temporal phylogenies with <0.10 posterior probability are indicated with grey X marks.
  Maximum likelihood phylogenies on the right are rooted via temporal regression in TreeTime.
  Note that x axes between maximum likelihood phylogenies are not consistent, as GP evolves faster than the genomic average and thus has more substitutions per site.
	}
	\label{trees}
\end{figure}

\section*{Results}

\subsection*{Loss of phylogenetic signal}
% In the past amplifying smaller fragments of pathogen genomes was often a pragmatic compromise between the cost of sequencing and information content, leading to sequencing of short but rapidly evolving pathogen genes or genomic regions.
% What few sequences were available were often collected months apart or across large geographic areas, ensuring that many sequences were genetically distinct either via mutations occurring in the intervening time or through prior population differentiation.
% However, in outbreak scenarios shorter genome fragments often do not accumulate mutations at a pace rapid enough to be of much use over short timescales.

Figure \ref{trees} shows the reconstructed phylogenies in substitution space (right) and time space (left) for 600 complete Ebola virus genomes (top) or just GP sequences (bottom).
Although higher levels of divergence are observed in the GP dataset (note that x axes between genome and GP phylogenies are not consistent), as seen from tree height, the differences in the number of non-polytomic nodes between genomic and GP data are clear, indicating substantially better resolution in disentangling the exact relationships between lineages in the former.
Figure \ref{embedding} shows where in the better resolved maximum likelihood phylogeny of genome sequences mutations that occurred in just the region spanning the GP gene.
Internal branches of a phylogeny correspond to hypotheses of common ancestry and in the case of GP only 42 internal nodes are identified in the maximum likelihood phylogeny compared to 210 internal nodes for complete genomes.
The few aspects of the West African epidemic that can be inferred from both GP and genome phylogenies, only the virus' origins in Guinea are clear, with details of its onwards spread largely lost in the GP phylogeny.
Genomic data, on the other hand, despite a reduction from over 1600 sequences described in the original study \citep{dudas_virus_2017} down to just 600, still contain information about the role of Sierra Leone's epidemic in maintaining transmission across the region through both endemic proliferation of lineages and their spread to neighbouring countries.

Unlike maximum likelihood phylogenies where branch lengths are directly proportional to the expected number of substitutions, branch lengths in temporal phylogenies are usually smoothed out by the fact that a range of dates are compatible with a given number of mutations on a branch.
Thus even large polytomies can be resolved into a branching structure derived from the tree prior, albeit without much support for any given configuration.
This can be seen in Figure \ref{trees}, where temporal phylogenies (left) appear to have similar degrees of resolution, yet the GP dataset (bottom) contains more nodes with less than 0.10 posterior support (marked by grey crosses).
Similarly, there is a noticeable degree of branch clustering by country in the GP temporal phylogeny, possibly caused by proximity of locations within country, which in the absence of genetic information cannot be resolved to the same degree as with genomic data.

In contrast to the maximum likelihood phylogeny of GP on the right (Figure \ref{trees}) its corresponding temporal phylogeny on the left exhibits a reconstruction of the West African epidemic largely consistent with what has been established previously \citep{dudas_virus_2017}.
This is likely to be caused by the combined effects of two sources of information.
First, additional information is added by specifying the collection dates for sequences, which might exclude certain topologies from being considered during MCMC on account of the relatively small effective population size of Ebola virus in West Africa.
Second, the generalised linear model approach to inferring migration is information-rich as it provides over 3000 possible parameter values (pairwise migration rates between locations) per predictor matrix, and thus if a few branches are strongly selecting for a ``correct'' predictor matrix to be included in the migration model that predictor matrix can then be used to determine the likely locations of branches for which less information is available.
However, a simpler continuous time Markov chain model where each individual pairwise migration rate is inferred individually in a maximum likelihood framework exhibits broadly similar patterns too (Figure \ref{TTtrees}).

\begin{figure}[h]
 \centering
	\includegraphics[width=0.6\textwidth]{figures/fig2_dates.png}
	\caption{\textbf{Masked tip date inference from genomes (left) and GP sequences (right).}
  Inferred collection dates in the masked set based on genomes (red, left) and GP sequences (blue, right).
  Each vertical line corresponds to the 95\% highest posterior density for the inferred tip date (y-axis), coloured red (genome) or blue (GP) if it falls within the true collection date (x-axis) and black otherwise.
  Dashed diagonal line indicates the 1-to-1 line.
  A histogram of residual errors (accuracy) between mean posterior date estimate and true date for each masked tip is shown in the second row.
  Third row shows the histogram of confidence interval widths for date estimates (precision).
	}
	\label{dates}
\end{figure}

\subsubsection*{Loss of temporal information}

Inferring masked tip dates from 10\% of the sequences (Figure \ref{dates}) is an intuitive way to show both the inherent noisiness of molecular clock estimates, as reflected in the width of 95\% highest posterior density intervals for inferred dates, and the differences in temporal resolution between GP and genome alignments.
True collection dates for genomes are mostly (56 out of 60, corresponding to a coverage probability of 0.93) within the 95\% highest posterior density of estimated dates, and the mean absolute error is $\approx$22 days across all masked tips.
In contrast, the 95\% HPDs for inferred dates in the GP dataset capture more of the true dates (58 out of 60, coverage probability $\approx$0.96) at the cost of markedly reduced precision, with mean absolute error going up to $\approx$106 days or $\sim$3.5 months.
Despite having lower coverage probability, more precise date estimates are derived from complete genomes with an average 95\% HPD width of $\approx$102 days, compared to $\approx$458 days for GP.
Another way of thinking about where the loss of information occurs is to consider root-to-tip against tip date regressions shown in Figure \ref{rtt}, where waiting times for mutations are too long to estimate the slope of the regression reliably, as every new mutation is seen across sequences collected over a longer interval of time.
Observed errors (Figure \ref{dates}, but also Figure \ref{TTdates} for maximum likelihood equivalent) for both datasets are very close to theoretical expectations calculated using Equation \ref{horizon}: 22 (observed) versus 20 (expected) days for Ebola virus genomes, and 106 (observed) versus 113 (expected) days for GP.
Also note that for many tips in the GP data set independent Markov chains converged onto different dates for masked tips (\textit{i.e.} local maxima) resulting in multi-peaked posterior samples after combining independent analyses.

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{figures/fig3_locations.png}
	\caption{\textbf{Masked tip location inference from genomes (left) and GP sequences (right).}
  Horizontal bars indicate the posterior distribution of masked tip locations, coloured by country (Sierra Leone in blue, Liberia in red, Guinea in green) and location (lighter colours indicate administrative divisions lying towards west of the country).
  The correct location of each tip is outlined in white, with the smaller plot to the right showing only the posterior probability of the correct location.
  Bars marked with an asterisk indicate cases where the correct location is within the 95\% credible set.
  Posterior distribution of probability-weighted distances between population centroids of inferred and correct locations is shown at the bottom with mean indicated by a tick mark.
	}
	\label{locations}
\end{figure}

\begin{figure}[h]
 \centering
  \subfloat{
  \includegraphics[width=0.45\textwidth]{figures/figXA_histories.png}
  }
  \subfloat{
  \includegraphics[width=0.45\textwidth]{figures/figXB_histories.png}
  }
  \\
  \subfloat{
  \includegraphics[width=0.45\textwidth]{figures/figXC_histories.png}
  }
  \subfloat{
  \includegraphics[width=0.45\textwidth]{figures/figXD_histories.png}
  }
  \caption{\textbf{Posterior traces of ancestral locations and posterior migrations for four Ebola virus lineages from genomes (top) and GP sequences (bottom).}
  The inferred ancestral branch location is logged at time points along the path from selected tips to the root of the tree, across the posterior distribution of trees.
  The smoothed trajectories are an indication of where and when a lineage that gave rise to a particular tip is inferred to have existed.
  Maps on the right show migration events that are inferred to have taken place, coloured by their posterior probability, with migrations with <0.05 posterior support are shown as dotted white lines.
  All lineages trace back to Gu\'{e}ck\'{e}dou prefecture of Guinea (white outline in the map), where the original zoonotic transmission event occurred near the Guinean border with Sierra Leone and Liberia.
  Some lineages are also descended from an early spillover event into Sierra Leone.
  }
	\label{trace}
\end{figure}

\subsubsection*{Migration model is strongly informed by tip dates and locations}

Differences between genomic and GP datasets are clear and dramatic when looking at both phylogenies (Figure \ref{trees}) and masked date inference (Figure \ref{dates}), but less pronounced when trying to infer the location of a masked tip (Figure \ref{locations}).
Although locations are correctly inferred more often and with greater support in genomic sequences compared to just the GP gene, there are numerous tips whose locations are not correctly inferred even from genome sequences (Figure \ref{locations} and Figure \ref{TTlocations} for maximum likelihood equivalent).
This might reflect the nature of these parameters of interest, since phylogenies and date inference ultimately draw information from mutation accumulation via relatively straightforward models of sequence evolution with limited parameter space.
In contrast, migration processes are far more complicated and nuanced without a \textit{de facto} standard for modelling, though continuous time Markov chain (CTMC) approaches are widely used \citep{lemey_bayesian_2009} with most advanced methods relying on generalised linear models without excessive over-parameterisation \citep{faria_simultaneously_2013,lemey_unifying_2014,dudas_virus_2017}.
Despite the lack of strong contrast in power to infer masked locations between genomes and GP sequences, cross entropies indicate better performance with complete genomes (6054.631 nats) than with GP (9905.726 nats).

Similarly, locations are inferred correctly more often with complete genomes than with GP sequences, where the maximum probability location (\textit{i.e.} the model's best guess) matches the truth, where using complete genomes results in 0.540 probability of guessing correctly compared to 0.286 probability for GP (for a calibration of both models see Figure \ref{calibration}).
The model makes these guesses with more certainty too, where the mean probability of the true location is 0.482 with genomes and 0.219 with GP, and mean probability of best guess (\textit{i.e.} maximum probability) is 0.680 and 0.396, respectively.
% \tbc{Need to more carefully define what you mean by `inferred correctly'. Cross-entropy does this well, otherwise need a cut-off for assignment. Over 50\%?}
We also calculated the great circle distances between the population centroids of true and each predicted location weighed by probability, which should ideally be 0.0 (0 km distance multiplied by probability of 1.0).
The mean of these distances across masked tips are 75.886 kilometres for genomes compared to 164.309 km for GP sequences.

In addition to assessing how well tip locations can be inferred from genetic information we also looked at how well historical patterns were reconstructed from sequence data.
To accomplish this we looked at the posterior distribution of ancestral locations of lineages that gave rise to four sequences in the data.
The four lineages were chosen for their well-characterised histories in the broader epidemic as well as complexity of migration.
One of these is strain `14859\_EMLK', a virus descended from the initial sweep of Ebola virus through Sierra Leone via Kailahun and Kenema districts which eventually ended up in Conakry (Guinea) from where it jumped back into Sierra Leone late in the epidemic where it was sequenced \citep{arias_rapid_2016}.
`EM\_004422', which migrated through Kailahun district of Sierra Leone too, but then spread into Liberia from which it spilled back into Guinea via Macenta prefecture before ending up in Kissidougou (Guinea) where it was sequenced \citep{carroll_temporal_2015}.
Similar to other lineages, `MK3462' was part of the sweep through Sierra Leone, though unlike others remained in-country, migrating to the environs of Freetown and then Bombali district where it was sequenced \citep{arias_rapid_2016}.
`PL5294', unlike others, belonged to a lineage that was not part of the Sierra Leonean sweep and instead part of an unusual and under-sampled lineage endemic to western Guinea (``lineage A'', \citep{carroll_temporal_2015}), from where it spilled into Sierra Leone's Kambia district late in the epidemic \citep{arias_rapid_2016}.

The histories of these four tips are, for the most part, reconstructed from both GP sequences and genomes consistently (Figure \ref{trace}), likely as a result of additional information brought in by specifying tip dates and their collection locations.
In addition, genomic data tend to concentrate the probability mass towards a single location at any given time, in contrast to GP sequences where several locations can be considered with non-negligible probabilities at numerous time points (Figure \ref{trace} and Figure \ref{trace_entropy}).
What is even more apparent is that without the additional information available when using complete genomes MCMC explores a wider variety of low-probability migration paths, as indicated by maps on the right of each plot in Figure \ref{trace}.
In the case of `EM\_004422', for example, a series of migrations through distant Conakry (western Guinea) are reconstructed with relatively high confidence from GP sequences, compared to shorter distance migrations that run through neighbouring Liberia reconstructed from genomes.

\begin{figure}[ht]
 \centering
	\includegraphics[width=0.75\textwidth]{figures/fig4_glm.png}
	\caption{\textbf{Correlates of migration identified from genomes (red) and GP sequences (blue).}
  Effect size and direction of correlation between predictor matrices and migrations are shown as half violin plots, where the top kernel density estimates (in red) are derived from genomes and bottom kernel density estimates (in blue) are derived from GP sequences, conditioned on the predictor matrix being included in the model.
  Kernel density estimates of coefficients where predictors have <3 Bayes factor support are outlined in dashed lines.
  Posterior inclusion probabilities are shown on the right (red for genomes, blue for GP sequences) with appropriate Bayes factor cutoffs indicated by dashed lines.
	}
	\label{glm}
\end{figure}

Despite markedly reduced information content for both total number of sequences (>1600 to 600) and additional loss of information in GP ($\approx$90\% fewer sites) sequences, the same core correlates of migration are recovered for both datasets in the generalised linear model (Figure \ref{glm}) compared to previous findings using all available sequence data \citep{dudas_virus_2017}.
These are: population sizes at origin and destination locations, within country migration effect, and great circle distances, which are identified as strong predictors of migration with high (>50 Bayes factor, BF), albeit not categorical, support (Figure \ref{glm}).
Four other migration predictors for the GP dataset have support >5 BF and <15 BF, which are international and national border sharing, Liberia-Guinea asymmetry, and index of temperature seasonality at origin.
Of these Liberia-Guinea asymmetry and international border sharing are also found to be good predictors of migration in genomic data, though confusingly Liberia-Guinea asymmetry has the opposite correlation sign with GP sequence data.
Apart from this deviation, predictors for both genome and GP gene datasets mostly have the same sign and very similar effect sizes.
As mentioned previously (Figures \ref{trees} and \ref{trace}), this suggests substantial amounts of information being derived from collection dates and locations of tips rather than genetic information.
The reduction in total numbers of sequences, as well as reduced phylogenetic information in the GP dataset appears to enable the migration model to explore combinations of predictors that would otherwise be confidently excluded with complete genomes and thus a larger number of predictor matrices is included in the migration model with low probabilities.
The differences between genomic and GP data, though seemingly small (\textit{e.g.} Figure \ref{locations}) is more pronounced when looking at total entropy of inclusion probabilities: 1.285 nats for genome data, and 2.688 for GP sequences.

\subsubsection*{Temporal resolution}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{figures/fig5_contours.png}
	\caption{\textbf{Mean waiting times for a mutation as a function of alignment length and evolutionary rate.}
  Contours correspond to mean waiting times under a given combination of alignment length and evolutionary rate.
  Genomes and barcode genes for a variety of viruses are shown with reported evolutionary rate confidence intervals (vertical lines), including analyses of Ebola virus genomes (red violin) and GP sequences (blue violin) reported here.
  Most genomes occupy parameter space implying temporal resolution of a mutation once every month or so, with mumps virus as an exception.
  Sub-genomic fragments on the other hand are expected to have mean mutation waiting times of more than a month.
	}
	\label{contours}
\end{figure}

As discussed in the introduction, the mean waiting for a mutation is 1/\textit{RL} (Equation \ref{horizon}) and depends on the rate at which mutations arise and are sampled by sequencing (evolutionary rate, \textit{R}) and number of sites under observation (alignment length, \textit{L}).
Since 1/\textit{RL} defines a linear relationship between rate \textit{R} and length \textit{L} mean waiting times for mutation can be reduced by an increase in either \textit{R} or \textit{L}.
In order to double temporal resolution one can either double the evolutionary rate \textit{R} or double the alignment length \textit{L}.
The former is generally outside the researchers' control, though genomic regions evolving at a faster rate exist in many pathogens.
How much faster smaller regions evolve will depend on forces of population genetics, such as ability to recombine with respect to the rest of the genome (strength of Hill-Robertson effect \citep{hill_effect_1966}), as well as positive selection or functional constraints.
It is thus unlikely that significantly higher rates will offset the reduction in resolution caused by focusing on a very small genomic region.
Extending the region that is sequenced, on the other hand, is often trivial outside of resource-limited areas and can dramatically improve temporal resolution.

To help researchers intuit the impact of sequence length and evolutionary rate on temporal resolution we show the relationship between evolutionary rate and alignment length in determining mean waiting times until a mutation is observed in Figure \ref{contours}.
In addition to theoretical expectations we also show where a variety of viral pathogens fall along the two axes - estimated evolutionary rates with uncertainty intervals on the y-axis and alignment length on the x-axis.
Sub-genomic alignments shown in Figure \ref{contours} include the small hydrophobic (SH) gene of mumps virus \citep{cui_evolutionary_2017} and glycoprotein (GP) sequences of Ebola virus analysed in this study, as well as sequences of two human influenza A viruses - genome of subtype H1N1/09 \citep{hedge_real-time_2013}, and haemagglutinin sequences of subtypes H1N1/09 \citep{smith_origins_2009} and H3N2 \citep{rambaut_genomic_2008}.
With respect to temporal resolution influenza A virus HAs are expected to acquire a mutation every one to two months on average, compared to around three to six months for Ebola virus GP and over a year for mumps virus SH.
Though all of these sequences are from (-)ssRNA viruses, SH and GP genes are part of a single non-recombining RNA genome \citep{chare_phylogenetic_2003}, whereas HA genes of influenza A viruses are encoded on their own segment which can be unlinked from their genomic background via reassortment.
Because Ebola and mumps virus genomes do not recombine, their polymerases may have been selected for higher fidelity due to Hill-Robertson effect \citep{hill_effect_1966}.

Complete genomes, on the other hand, occupy parameter space that implies that a new mutation occurs on average every month or every few weeks.
This is achieved through having more sites rather than substantial differences in evolutionary rates, which differ only marginally with respect to subgenomic fragments.
Despite this, no virus is expected to acquire mutations faster than about once per week on average, and the two genomes with highest predicted temporal resolution - MERS-CoV and H1N1/09 - are difficult to analyse due to recombination and reassortment, respectively, though advances are being made in modelling reticulate evolution \citep{vaughan_inferring_2017}.
The inverse relationship between observed evolutionary rate and sequence length is similar, but not the same as the relationship between virus genome sizes and mutation rates, where high mutation rates and large genome sizes lead to substantial deleterious mutation load \citep{pybus_phylogenetic_2007,gago_extremely_2009}.
This upper limit on mutation waiting times set by optimal evolutionary rates is what we refer to as the temporal horizon - population processes with inverse of rate (\textit{i.e.} waiting time) less than the rate at which a pathogen acquires mutations will not be captured with high fidelity by currently existing methods.
The exact relationship between mutation waiting times and rates of processes will, of course, be complicated by the presence of co-circulating lineages, site-wise rate heterogeneity, and choice of model for population processes of interest.

\section*{Conclusions}
\subsubsection*{Theoretical considerations}
For studies focused on temporal dynamics of pathogens over shorter periods of time the waiting time for a mutation should ideally be smaller than the inverse of the rate at which a process of interest occurs.
Serial interval is often of most interest usually and has been addressed previously \citep{campbell_when_2018,grubaugh_tracking_2019}, but migration or cross-species transmission rates could also exceed the critical temporal resolution threshold if sequences are assigned to compartments that are too small.
It is likely that this resolution limit will be improved greatly in the future by including additional information, either some aspects of a known transmission tree or, more likely, pathogen variation at the within-individual level, where variant sharing between two or more individuals is evidence of their linkage in a transmission cluster.
Much like evolutionary rates, these methods might encounter biological limits outside of researchers' control, however.

In addition to emphasising the need to sequence complete pathogen genomes, we also hope that our study imparts the interpretation of pathogen evolutionary rates as primarily a parameter indicating temporal resolution of sequence data, rather than a parameter of particular biological relevance.
There have been previous incidents were a misunderstanding of the relationship between evolutionary rates and alignment length has been used to argue that low within-outbreak divergence in Ebola virus GP during the outbreak in Kikwit (Democratic Republic of Kongo) in 1995 was evidence of ``genetic stability'' \citep{rodriguez_persistence_1999}.
What is far more likely to have taken place, however, is the phenomenon we show with our GP data (Figures \ref{trees} and \ref{embedding}), where even after more than two years of the West African epidemic the GP gene is too short to accumulate appreciable numbers of mutations.
Higher reported evolutionary rates early in the West African epidemic \citep{gire_genomic_2014} have also been misreported as having biological meaning, though not by the original study \citep{holmes_evolution_2016,rambaut_comment_2016}, and arose through intense sequencing of a single transmission chain where mildly deleterious viral variants might not have been purged by purifying selection.
We hope that our study clarifies that evolutionary rates are primarily a parameter of statistical resolution, rather than of evolutionary forces, and on their own are not sufficient to correctly interpret molecular clock data.
Ideally, in the future sequence length and elapsed time will be included next to evolutionary rate estimates in order to transparently communicate statistical power available for analysis.

There is an additional Bayesian phylogenetic argument to be made in favour of using complete genomes.
Molecular clock phylogenetics often relies on Markov chain Monte Carlo sampling to approximate the posterior distribution of phylogenetic trees \citep{yang_bayesian_1997}.
Sequences which fall into polytomies in substitution phylogenies (\textit{i.e.} well-defined common ancestry, but no indication of exact branching order) are particularly problematic, since plausible temporal phylogenies can be reconstructed in the absence of mutations.
The branching order of such clades in time trees will be determined via tree and molecular clock rate priors, since no information about branching order can be recovered from the sequences themselves.
There are over 34 million possible rooted trees for a set of 10 sequences, but many of these might not be visited during MCMC if, for example, sequences are collected over time and effective population size ($N_{e}$) is low.
Nonetheless, MCMC is particularly inefficient at sampling tree topologies for identical sequences \citep{whidden_quantifying_2015}, since increasing the number of identical sequences leads to expansion of search space without adding additional information that could constrain the search.
Until reliable methods are developed and standardised the current solution is to reduce the numbers of identical sequences going into temporal MCMC analyses.

\subsubsection*{Practical considerations}
As well as temporal resolution concerns raised previously there are practical issues to consider when sequencing pathogens.
Although many pathogens have established ``barcode'' genes or regions \citep{towner_rapid_2004}, some do not.
This can easily lead to different groups sequencing different pathogen genes by chance or choice, as has happened with Ebola virus previously, where GP \citep{georges-courbot_isolation_1997}, a short fragment of the polymerase \citep{leroy_fruit_2005}, or nucleoprotein \citep{rouquet_wild_2005} were sequenced, which is not necessarily a problem when sufficient complete genomes are available to bridge information between disparate regions and appropriate methods of analysis are used \citep{dudas_phylogenetic_2014}.
Sequencing complete pathogen genomes, in addition to providing the best possible resolution temporally in terms of mutation content (Figure \ref{contours}), also ends up aiding in standardising data between studies, in the sense that a sequenced genome is a complete unit of data and there is nothing more to be done for sequence data except gathering better metadata.

It is also worth considering that the lifetime of sequence data extend beyond publication.
Most scientific studies are designed with specific questions in mind that guide how data are collected and analysed to improve the researchers' ability to detect differences.
This makes combining data across studies with different goals (and correspondingly different data and approaches to analysing them) challenging.
Sequence data, on the other hand, only become difficult to combine when sequences are too diverged to reliably align or are too numerous to infer phylogenies in reasonable time.
Since divergence levels are generally low within outbreaks (with exceptions \citep{andersen_clinical_2015}), sequence data are often trivial to combine.
More than that, including sequence data from previous studies can reciprocally contextualise both older and newer sequences (\textit{e.g.} \cite{mena_origins_2016}).
What remains problematic is determining and standardising additional data pertaining to the sequences themselves (``metadata'') in a way that makes sequence data easy to use by other groups.
Whilst date and location of collection are widely reported and often of most interest, non-standard encodings of both are seen on public databases.

\subsubsection*{Stating the obvious}
It is not at all surprising that reducing the number of alignment columns by 10\% from nearly 19,000 nucleotides that comprise the entire Ebola virus genome down to around 2,000 nt of the GP gene can result in loss of information, even if this shorter region evolves at a markedly faster rate.
Here, we have quantified this loss of information via several methods: raw phylogenetic resolution (Fig \ref{trees}), molecular clock signal (Fig \ref{dates}), and aspects of migration model (Figs \ref{locations}, \ref{trace}, and \ref{glm}).

In most cases biological aspects of the data, such as precise branching order and molecular clock resolution, suffer from severe loss in temporal resolution (Figure \ref{dates}), whereas modelling of non-biological aspects of the data, \textit{i.e.} migration, tend to be more robust (Figures \ref{locations} and \ref{glm}).
This is very likely to be caused by temporal and geographic, rather than genetic features of the sequence data \citep{boskova_influence_2018}.
A clustering of sequences from a particular location collected over a short period of time is likely to be a genuine outbreak cluster within a wider epidemic and in the absence of genetic information phylogeographic models tend to group sequences by location.
This might explain why in many cases when comparing analysis results between genome and GP datasets statistical power in migration model remains disproportionately high, despite retaining only ~10\% of available sites and mutations and results between the entire >1600 genome data set \citep{dudas_virus_2017} is very similar to the reduced data set analysed here.
On a similar note, case numbers alone have been used to recover a gravity-like model for the spread of Ebola virus in West Africa \citep{kramer_spatial_2016} previously, further arguing that the clustering of cases in time and space contains sufficient information about the movement of Ebola virus in West Africa.
The overall conclusion from our study, as well as others \citep{wohl_co-circulating_2018}, is that sequencing short genomic regions, instead of whole genomes is an ill-advised practice for investigating infectious disease outbreaks in any appreciable detail across relatively short timescales.

\section*{Methods}
\subsubsection*{Sequence data}
A publicly available dataset of 1610 Ebola virus genomes sequenced by various groups \citep{baize_emergence_2014,gire_genomic_2014,park_ebola_2015,carroll_temporal_2015,kugelman_monitoring_2015,ladner_evolution_2015,simon-loriere_distinct_2015,tong_genetic_2015,arias_rapid_2016,smits_genotypic_2015,quick_rapid_2015} and systematised in \cite{dudas_virus_2017} was filtered to remove sequences where over 1\% of the genome sequence was ambiguous or the precise location down to administrative division was not available, leaving 943 genomes.
A set of 600 viral genomes were randomly sampled from the filtered dataset of 943 high quality genomes.
Of the 600 genomes that were chosen for analysis 10\% (60 genomes) were chosen for masking, where for all subsequent analyses both the date and location were considered as unknown and inferred as latent variables.
Date inference was constrained to the period 2013 December 01 to 2015 December 01, corresponding roughly to the presumed beginning of the epidemic in late 2013 and its end in autumn of 2015.
Another dataset was generated by extracting the glycoprotein GP coding sequence (with padding inserted into the polymerase slippage site to bring it in-frame) from the complete genomes dataset, resulting in an alignment 2031 nucleotides long.

\subsubsection*{Bayesian analyses}
Both GP and genome datasets were analysed in BEAST v1.8.10 \citep{suchard_bayesian_2018} under the generalised linear model (GLM) described previously \citep{faria_simultaneously_2013,lemey_unifying_2014,dudas_virus_2017} to infer the migration model.
Sites in both GP and genome alignments were partitioned into codon positions 1, 2, and 3, with the genome analysis also including a partition comprised of non-coding intergenic regions.
Each partition was assigned an independent HKY+$\Gamma_{4}$ \citep{hky_1985,yang_1994} substitution model.
A relaxed molecular clock \citep{drummond_2006} with an uninformative prior on the mean \citep{ferreira_bayesian_nodate} of the log-normal distribution was used as the clock model.
A flexible skygrid tree prior \citep{gill_2013} was used to infer estimates of effective population size across 100 evenly spaced points in time starting 1.5 years prior to the collection of the most recent sequence to the date of the most recent sequence.

Both analyses (genome and GP) were set to run for 500 million states, sampling  every 50,000 states and run three (genome) or seven (GP) times independently.
Due to limited computational resources many analyses did not complete the full run and so for full genomes only 136.5, 8.62, and 143.8 million states were sampled, though after combining independent chains effective sample size (ESS) values are nearly the recommended 200.
Similarly for GP only two MCMC analyses ran their allotted 500 million with others running to 259.9, 253.9, 255.8, 261.65, and 261.5 million states.
Unlike complete genome MCMC analyses, GP analyses exhibit relatively poor ESS values even after combining seven independent chains, indicative of bad mixing in the absence of additional data contained in complete genome sequences.
Convergence issues and appropriate burn-in values were assessed with Tracer v.1.7 \citep{rambaut_posterior_2018}, where 50 million states from every analysis (genome and GP) was discarded as burnin.

Posterior distributions of inferred tip dates for the masked set were logged during MCMC and 95\% highest posterior density intervals were computed using a custom Python script, due to multi-peaked posterior distributions after combining independent analyses.
Posterior distributions of trees were summarised as maximum clade credibility (MCC) trees using TreeAnnotator \citep{suchard_bayesian_2018}.
Inferred posterior probabilities of masked tip locations were recovered from MCC trees.
Ancestral location probabilities were recovered via a modified version of baltic's samogitia.py (\url{https://github.com/evogytis/baltic/blob/master/samogitia.py}) across 200 equally spaced time points between mid-2013 and beginning of 2016.

\subsubsection*{Maximum likelihood analyses}
RAxML \citep{stamatakis_raxml_2014} was used to infer maximum likelihood phylogenies for genome and GP datasets under the same partitioning as described for Bayesian analyses: three codon position partitions for GP and genome, with genomes having an additional partition for intergenic regions under independent GTR+CAT substitution models.
Trees were rooted in TreeTime according to best r$^{2}$ value for root-to-tip against collection date regression with the 2 year constraint used for masked tips described earlier.
A temporal phylogeny with marginal reconstruction of most likely dates for masked tips was carried out in TreeTime \citep{sagulenko_treetime:_2018} as well.
Ancestral sequences at internal nodes of the clock-rooted RAxML topology were inferred using TreeTime under an HKY model \citep{hky_1985} of evolution.
Ancestral location states were inferred in TreeTime using a continuous time Markov chain model identical to the one used by \cite{lemey_bayesian_2009} without the Bayesian stochastic search variable selection.
We also repeated many of the analyses under a maximum likelihood model in TreeTime \citep{sagulenko_treetime:_2018}, like inference of masked tip dates (figure \ref{TTdates}) and locations (figure \ref{TTlocations}).


\subsubsection*{Error computation}
For figure \ref{dates} mean absolute errors were computed as
\begin{equation}
    \epsilon = \frac{1}{N} (\sum_{i=1}^{N} (t_{i} - \sum_{m=1}^{M} e_{i}))
    % \eta = mean across tips (true date - posterior mean)
\end{equation}

Where N is the number of masked tips, $t_{i}$ is the true date of the \textit{i}th masked tip, $e_{i}$ is the estimated date of the \textit{i}th masked tip, and M is the number of states  sampled from the posterior distribution.

For figure \ref{locations} errors expressed in units of distance were calculated as
\begin{equation}
  \epsilon = \frac{1}{N} (\sum_{i=1}^{N} (\sum_{j=1}^{J} \Delta(t_{i},e_{j})\times p_{ij}))
\end{equation}

Where N is the number of masked tips, J is the number of locations in the migration model, $\Delta$ is great circle distance in kilometres, $t_{i}$ is the coordinate of the population centroid of the true location of the \textit{i}th masked tip, $e_{j}$ is the coordinate of the population centroid of \textit{j}th location, and $p_{j}$ is the probability that the \textit{i}th tip is in \textit{j}th location.

Entropies for predictors shown in figure \ref{glm} and location probabilities in figure \ref{trace_entropy} were calculated as
\begin{equation}
  S = -\sum_{i} P_{i} log_{e}(P_{i})
\end{equation}

where $P_{i}$ is the mean posterior inclusion probability of \textit{i}th predictor matrix in the model for figure \ref{glm}, and probability of \textit{i}th location for figure \ref{trace_entropy}.

Cross entropies for figure \ref{locations} were calculated as
\begin{equation}
  H = -\sum_{i}^{N} log_{e}(q_{i})
\end{equation}

where N is the number of masked tips, $q_{i}$ is the probability of the true location of the \textit{i}th masked tip, which is assigned a probability of 0.0001 if the true location does not appear in the set of inferred possible locations (\textit{i.e.} has probability 0.0) to avoid domain error.

\subsection*{Data availability}
Sequence data and all analytical code is publicly available at \url{https://github.com/blab/genomic-horizon}.

\section*{Acknowledgements}
We would like to thank Andrew Rambaut for useful discussion and advice.
GD is supported by the Mahan postdoctoral fellowship from the Fred Hutchinson Cancer Research Center.
TB is a Pew Biomedical Scholar and is supported by NIH R35 GM119774-01.

\bibliographystyle{mbe}
\bibliography{genomic-horizon}

\newpage

\setcounter{figure}{0}
\setcounter{table}{0}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}


\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_embedding.png}
	\caption{\textbf{Whole genome maximum likelihood tree coloured by mutations occurring in GP.}
  Colours indicate the cumulative number of mutations from the root occurring in the GP gene.
  Much of the clade resolution is lost when only considering mutations occurring in the GP gene, particularly in the already highly polytomic Sierra Leonean part of the phylogeny in red.
	}
	\label{embedding}
\end{figure}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_treetimeTrees.png}
	\caption{\textbf{Maximum likelihood phylogenies of complete Ebola virus genomes (left) and GP sequences (right) with maximum likelihood ancestral location reconstruction.}
  Trees were inferred in RAxML \citep{stamatakis_raxml_2014} with ancestral state reconstruction performed in TreeTime \citep{sagulenko_treetime:_2018}.
  Inferred phylogeographic patterns are for the most part consistent with Bayesian results presented in Figure \ref{trees} with severe loss of statistical power when using GP instead of genome sequences.
	}
	\label{TTtrees}
\end{figure}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_rtt.png}
	\caption{\textbf{Root to tip regression for maximum likelihood trees of genome (red) and GP (blue) sequences.}
  Linear regression of sequence collection dates against distance from the root gives evolutionary rate estimates (slope of the regression) at $0.82\times10^{-3}$ and $0.73\times10^{-3}$ substitutions per site per year, respectively.
  Despite similar rates the correlation between collection dates and divergence from root is far better using genomes ($r^{2}=0.76$) than GP sequences ($r^{2}=0.13$).
	}
	\label{rtt}
\end{figure}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_treetimeDates.png}
	\caption{\textbf{Maximum likelihood inference of masked tip dates from genomes (red, left) and GP sequences (blue, right) using TreeTime.}
  Vertical bars indicate the 95\% confidence interval for marginal reconstruction of masked tip dates plotted against their true dates.
  Tip dates where the 95\% confidence interval excludes the true value are shown in black.
	}
	\label{TTdates}
\end{figure}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_treetimeLocations.png}
	\caption{\textbf{Maximum likelihood inference of masked sequence location from genomes (left) and GP sequences (right) via a CTMC model implemented in TreeTime.}
  Unlike the Bayesian GLM where probabilities are spread across different locations, the CTMC gives categorical support to one location.
  Genomes still perform better in terms of correct guess (0.432 probability that best guess location is true location for genomes versus 0.259 for GP), cross entropy (12012.800 nats for genome versus 24397.109 nats for GP) and mean probability-weighted great circle distance between true location population centroid and estimated location population centroid (2.304 km for genome versus 3.287 km for GP).
	}
	\label{TTlocations}
\end{figure}

\begin{figure}[h]
 \centering
	\includegraphics[width=0.75\textwidth]{supp_figures/sfigX_calibration.png}
	\caption{\textbf{Calibration curve for phylogeographic model informed with genome (red) and GP (blue) sequences.}
  Logistic regression of probability of the most likely location against whether it is correct or not for genome (red) and GP (blue) sequences with jitter introduced along the y axis to make points discernible.
  Overall performance of the phylogeographic model is comparable between genome and GP sequences, as indicated by sigmoid curves matching the 1-to-1 dotted line.
	}
	\label{calibration}
\end{figure}

\begin{figure}[h]
 \centering
  \subfloat{
  \includegraphics[width=0.45\textwidth]{supp_figures/sfigXA_locationEntropy.png}
  }
  \subfloat{
  \includegraphics[width=0.45\textwidth]{supp_figures/sfigXB_locationEntropy.png}
  }
  \\
  \subfloat{
  \includegraphics[width=0.45\textwidth]{supp_figures/sfigXC_locationEntropy.png}
  }
  \subfloat{
  \includegraphics[width=0.45\textwidth]{supp_figures/sfigXD_locationEntropy.png}
  }
  \caption{\textbf{Entropies of posterior ancestral location reconstruction from genomes (red) and GP sequences (blue) for four tips.}
  Ancestral state reconstructions from genomes typically have lower entropies relative to reconstructions derived from GP sequences, indicating better certainty in location assignment at any given time.
  Red and blue bars at the end of the plot indicate relative cumulative entropies of genome and GP sequence reconstructions, respectively.
  }
	\label{trace_entropy}
\end{figure}

\end{document}
